ğŸ¤– Local Jarvis AI â€” Offline RAG Chat Assistant

A fully offline AI-powered document assistant built using
ğŸ§  Ollama (Mistral + Embedding Model),
ğŸ“š LangChain + Chroma, and
ğŸ¨ Streamlit for an interactive chat interface.

This project lets you upload your own PDF notes or documents and then ask natural language questions.
The AI finds relevant context from your local files and responds intelligently â€” no internet or API key required.

ğŸš€ Features

ğŸ”’ 100% Offline (uses local Ollama models)

ğŸ“„ Upload and query your own PDFs

ğŸ§© Uses Retrieval Augmented Generation (RAG) for contextual answers

ğŸ§  Embeddings stored locally in Chroma vector database

ğŸ’¬ Interactive web interface using Streamlit

âš™ï¸ Built modularly with modern LangChain ecosystem

ğŸ§± Works with Mistral or LLaMA 3 models

ğŸ§° Tech Stack
Component	Purpose
Python 3.12+	Core programming language
Ollama	Local LLM hosting (Mistral / LLaMA 3 / Nomic Embed)
LangChain Community	Document loading, text splitting, and RAG logic
LangChain Core	Data structures and document schema
LangChain Chroma	Vector storage and retrieval
Streamlit	Frontend web app
ChromaDB	Local vector store for embeddings
ğŸ“¦ Folder Structure
local-jarvis-ai/
â”‚
â”œâ”€â”€ app_streamlit.py             # Main chat app (Streamlit UI)
â”œâ”€â”€ query_data.py                # Core query pipeline for RAG
â”œâ”€â”€ populate_database.py         # Loads and indexes PDFs into Chroma
â”œâ”€â”€ get_embedding_function.py    # Sets up local Ollama embeddings
â”œâ”€â”€ test_rag.py                  # Evaluation tests for QA
â”œâ”€â”€ requirements.txt             # Project dependencies
â”‚
â”œâ”€â”€ data/                        # Folder containing user-uploaded PDFs
â”‚   â”œâ”€â”€ Software Engineering.pdf
â”‚   â”œâ”€â”€ Data Structures and Algorithms.pdf
â”‚   â”œâ”€â”€ Networking Basics.pdf
â”‚   â””â”€â”€ Cloud Computing.pdf
â”‚
â”œâ”€â”€ chroma/                      # Vector database (auto-generated)
â””â”€â”€ README.md                    # Project documentation

âš™ï¸ Installation Guide
1ï¸âƒ£ Install Ollama

Download from https://ollama.com/download

Then verify installation:

ollama --version


Start the Ollama server (if not running automatically):

ollama serve

2ï¸âƒ£ Pull Required Models
ollama pull mistral
ollama pull nomic-embed-text
ollama pull llama3


Check available models:

ollama list


âœ… Expected:

mistral:latest
nomic-embed-text:latest
llama3:latest

3ï¸âƒ£ Set Up Python Environment

If using Miniconda:

conda create -n jarvis python=3.12 -y
conda activate jarvis


Then install dependencies:

pip install -r requirements.txt


If requirements.txt doesnâ€™t exist, manually install:

pip install streamlit langchain-community langchain-core langchain-chroma chromadb pypdf sentence-transformers pytest boto3

ğŸ§  Build Vector Database

Place your notes or PDFs in the data/ folder.

Then run:

python populate_database.py --reset


Expected output:

âœ¨ Clearing Database
ğŸ‘‰ Adding new documents: 169
âœ… Database updated and persisted successfully!

ğŸ’¬ Query Your AI Locally

Try a direct question from your terminal:

python query_data.py "What are the phases of SDLC?"


Example output:

The phases of SDLC include:
1. Requirement Analysis
2. Design
3. Implementation
4. Testing
5. Deployment
6. Maintenance

ğŸ–¥ï¸ Run the Streamlit App

Start the web interface:

streamlit run app_streamlit.py


Expected terminal output:

Local URL: http://localhost:8501
Network URL: http://192.168.x.x:8501


Now open the given local URL in your browser.

ğŸ—£ï¸ Chat with Jarvis

Once open, you can:

Upload new PDFs

Ask questions like:

What is cloud computing?
Difference between array and linked list?


See responses appear in real-time

View sources used from your uploaded files

âš¡ Common Fixes
âŒ AttributeError: 'Chroma' object has no attribute 'persist'

â†’ Install and use updated langchain-chroma:

pip install -U langchain-chroma


and replace:

from langchain.vectorstores.chroma import Chroma


with:

from langchain_chroma import Chroma

âŒ Import "langchain.schema" could not be resolved

â†’ Replace with:

from langchain_core.documents import Document

âŒ JSONDecodeError in Streamlit

â†’ Ollama returns multiple JSON lines. Fix by reading in streaming mode or parsing only first valid JSON object.

ğŸ§ª Test Setup

Run validation tests for question-answer quality:

pytest test_rag.py

ğŸ” Privacy

All processing happens locally â€”
no data leaves your machine.
Ollama, LangChain, and Chroma run offline, making this a secure personal assistant setup.

ğŸ’¡ Future Improvements

Add support for DOCX, TXT uploads

Stream typing animations (like ChatGPT)

Include voice input/output

Dockerize the entire setup for one-click deployment

ğŸ§‘â€ğŸ’» Author

Gourish M.
ğŸ“˜ MCA Student @ Kristu Jayanti College
ğŸ’¬ Interested in AI, Data Analysis, and Web Development

ğŸ Quick Summary
Command	Purpose
ollama serve	Start Ollama server
ollama list	Check available models
python populate_database.py	Build vector DB from PDFs
python query_data.py "<question>"	Ask a question
streamlit run app_streamlit.py	Launch chat UI