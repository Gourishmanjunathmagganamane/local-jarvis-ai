<h1 align="center">ğŸ¤– Local Jarvis AI</h1>

<p align="center">
  <b>ğŸ’¬ Your Offline, Privacy-First AI Assistant</b><br>
  Built with <a href="https://ollama.ai" target="_blank">Ollama</a> ğŸ¦™ | <a href="https://www.langchain.com" target="_blank">LangChain</a> ğŸ§  | <a href="https://streamlit.io" target="_blank">Streamlit</a> âš¡
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.12+-blue?logo=python" />
  <img src="https://img.shields.io/badge/LLM-Mistral%7CLLaMA3-green?logo=openai" />
  <img src="https://img.shields.io/badge/Database-ChromaDB-purple?logo=databricks" />
  <img src="https://img.shields.io/badge/UI-Streamlit-red?logo=streamlit" />
  <img src="https://img.shields.io/badge/Status-Offline%20AI-success?logo=github" />
</p>

---

## ğŸ§  Overview

**Local Jarvis AI** is an **offline RAG-based assistant** that can read your PDFs, learn from them, and answer questions instantly.  
All processing happens **locally** using **Ollama**, **LangChain**, and **ChromaDB** â€” keeping your data private and secure.

> âš™ï¸ Think ChatGPT â€” but completely offline and personalized to your own study material.

---

## ğŸ¯ Features

âœ… Runs **fully offline** (no API key or internet needed)  
ğŸ“„ Upload **PDF / TXT / DOCX** notes  
ğŸ§© Uses **Retrieval Augmented Generation (RAG)**  
âš¡ Answers powered by **Mistral / LLaMA 3**  
ğŸ’¬ Interactive **Streamlit chat interface**  
ğŸ“š Shows **sources** for every answer  
ğŸ’¾ Embeddings stored locally via **Chroma Vector DB**

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|-------------|
| ğŸ§  LLM | Ollama (Mistral / LLaMA 3) |
| ğŸ“š Framework | LangChain (Community + Core) |
| ğŸ’¾ Vector DB | Chroma |
| ğŸ¨ Frontend | Streamlit |
| ğŸ Language | Python 3.12+ |

---

## ğŸ“ Project Structure
## ğŸ“ Project Structure

| File / Folder | Description |
|-------------------------------|----------------------------------------------|
| `app_streamlit.py` | Streamlit UI (frontend) |
| `query_data.py` | RAG query logic |
| `populate_database.py` | Loads and embeds PDFs into Chroma |
| `get_embedding_function.py` | Embedding setup (Ollama / LangChain) |
| `test_rag.py` | Unit testing and validation |
| `requirements.txt` | Python dependencies |
| `README.md` | Project documentation |
| `data/` | Folder containing your PDFs |
| `chroma/` | Auto-generated vector database |


yaml
Copy code

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Install Ollama

Download ğŸ‘‰ [https://ollama.com/download](https://ollama.com/download)

Verify:
```bash
ollama --version
Start Ollama in background:

bash
Copy code
ollama serve
2ï¸âƒ£ Pull required models
bash
Copy code
ollama pull mistral
ollama pull nomic-embed-text
ollama pull llama3
Check installed models:

bash
Copy code
ollama list
âœ… Example Output:

makefile
Copy code
mistral:latest
nomic-embed-text:latest
llama3:latest
3ï¸âƒ£ Set up environment
If using Miniconda:

bash
Copy code
conda create -n jarvis python=3.12 -y
conda activate jarvis
Then install dependencies:

bash
Copy code
pip install -r requirements.txt
If no requirements file:

bash
Copy code
pip install streamlit langchain-core langchain-community langchain-chroma chromadb pypdf sentence-transformers pytest boto3
4ï¸âƒ£ Add your notes or study PDFs
Place all your PDFs in the data/ folder:

kotlin
Copy code
data/
 â”œâ”€â”€ Data Structures and Algorithms.pdf
 â”œâ”€â”€ Networking Basics.pdf
 â”œâ”€â”€ Software Engineering.pdf
 â””â”€â”€ Cloud Computing.pdf
ğŸ§© Build Knowledge Base
Run:

bash
Copy code
python populate_database.py --reset
Expected output:

pgsql
Copy code
âœ¨ Clearing Database
ğŸ‘‰ Adding new documents: 169
âœ… Database updated and persisted successfully!
ğŸ’¬ Query from Terminal
Ask directly:

bash
Copy code
python query_data.py "What are the phases of SDLC?"
Example output:

markdown
Copy code
The phases of SDLC are:
1. Requirement Analysis
2. Design
3. Implementation
4. Testing
5. Deployment
6. Maintenance
ğŸ–¥ï¸ Launch Streamlit Chat UI
Run:

bash
Copy code
streamlit run app_streamlit.py
Then open the URL displayed:
ğŸ‘‰ http://localhost:8501

Ask questions like:

pgsql
Copy code
What is cloud computing?
Difference between array and linked list?
ğŸ§  How It Works (RAG Flow)
1ï¸âƒ£ PDFs are read and split into small chunks
2ï¸âƒ£ Chunks are embedded using nomic-embed-text
3ï¸âƒ£ Stored in Chroma Vector DB
4ï¸âƒ£ When you ask something â†’ Top matching chunks are retrieved
5ï¸âƒ£ Mistral generates a detailed answer using that context
6ï¸âƒ£ Streamlit shows the response + sources

<p align="center"> <img src="https://github.com/microsoft/LLM-RAG-demo/raw/main/docs/rag-diagram.png" width="650"> </p>
âš¡ Common Issues & Fixes
Issue	Fix
âŒ AttributeError: 'Chroma' object has no attribute 'persist'	Use from langchain_chroma import Chroma and db._client.persist()
âŒ Import 'langchain.schema' could not be resolved	Use from langchain_core.documents import Document
âŒ JSONDecodeError in Streamlit	Add stream=True and handle multi-line JSON output

ğŸ§ª Testing
Run automated RAG tests:

bash
Copy code
pytest test_rag.py
ğŸ§± Future Enhancements
 Add DOCX and TXT support

 Typing animation (ChatGPT style)

 Microphone input & text-to-speech

 Dockerize for one-click setup

 Add dark/light theme toggle in Streamlit

ğŸ” Privacy
ğŸ›¡ï¸ 100% local processing
ğŸ§  Your data never leaves your machine
â˜ï¸ No cloud APIs or online storage used

ğŸ‘¨â€ğŸ’» Author
Gourish M.
ğŸ“ MCA Student @ Kristu Jayanti College
ğŸ’¡ Passionate about AI, Data, and Cloud
ğŸŒ GitHub

ğŸ Quick Reference
Command	Description
ollama serve	Start Ollama backend
ollama list	Check local models
python populate_database.py --reset	Rebuild vector DB
python query_data.py "<question>"	Query directly
streamlit run app_streamlit.py	Launch UI

<p align="center"> <b>ğŸš€ Local Jarvis AI â€” Your Personal Offline Knowledge Assistant</b><br> <i>â€œBecause your data deserves privacy.â€</i> </p> ```
âœ… Steps for you:
Copy everything above.

Open VS Code â†’ local-jarvis-ai/README.md

Paste â†’ Save.

Commit and push to GitHub:

bash
Copy code
git add README.md
git commit -m "Added rich README for Local Jarvis AI"
git push
